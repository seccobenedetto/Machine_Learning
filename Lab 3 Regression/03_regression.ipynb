{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning LAB 3: LINEAR REGRESSION\n",
    "\n",
    "Course 2024/25: *F. Chiariotti*\n",
    "\n",
    "The notebook contains some simple tasks to be performed with **LINEAR REGRESSION MODELS**.\n",
    "\n",
    "Complete all the **required code sections**.\n",
    "\n",
    "### IMPORTANT for the exam:\n",
    "\n",
    "The functions you might be required to implement in the exam will have the same signature and parameters as the ones in the labs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VR traffic prediction\n",
    "\n",
    "In this notebook, we will explore the prediction of Virtual Reality (VR) traffic. The data come from the paper:\n",
    "\n",
    "Lecci, Mattia, _et al._ \"An open framework for analyzing and modeling XR network traffic.\" IEEE Access 9 (2021): 129782-129795.\n",
    "\n",
    "The VR game Virus Popper was instantiated on a computer through the RiftCat application: the user could then see the virtual content on their phone, which was strapped to their head with a Cardboard viewer. The file virus_popper.csv contains three columns from the traffic capture:\n",
    "idx    | frame size (B) |  time (s)\n",
    "0      | 38424          |  0.0\n",
    "1      | 39801          |  0.01944\n",
    "...\n",
    "\n",
    "The game was run at 60 frames per second, with a target rate of 30 Mb/s. The task is then to predict the size of the next frame, given the past N frames. This was explored in another paper:\n",
    "\n",
    "Chiariotti, Federico, _et al._ \"Temporal characterization and prediction of vr traffic: A network slicing use case.\" IEEE Transactions on Mobile Computing 23.5 (2023): 3890-3908.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import all the necessary Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as rnd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import linear_model, preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "def load_dataset(filename):\n",
    "    data_train = pd.read_csv(filename)\n",
    "    data = data_train.iloc[:, 1].values # Get the second column (frame size) as the input\n",
    "    return data\n",
    "\n",
    "# Load the dataset\n",
    "data = load_dataset('data/virus_popper.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data and create training and test sets\n",
    "\n",
    "In this case, we are learning a time series: let us consider a memory of 2 samples, i.e., use X[n-1] and X[n-2] to predict X[n]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the dataset\n",
    "avg_size = np.mean(data)\n",
    "norm_data = np.asarray(data) / avg_size\n",
    "\n",
    "# Compute the splits and prepare the columns\n",
    "m_training = int(0.75*norm_data.shape[0])\n",
    "\n",
    "X_training = np.ones([m_training - 2, 3])\n",
    "X_training[:,1] = norm_data[: m_training - 2]\n",
    "X_training[:,2] = norm_data[1 : m_training - 1]\n",
    "Y_training = norm_data[2 : m_training]\n",
    "\n",
    "\n",
    "X_test = np.ones([norm_data.shape[0] - m_training - 2, 3])\n",
    "X_test[:,1] = norm_data[m_training : -2]\n",
    "X_test[:,2] = norm_data[m_training + 1 : -1]\n",
    "Y_test = norm_data[m_training + 2:]\n",
    "\n",
    "print(np.shape(X_training), np.shape(Y_training), np.shape(X_test), np.shape(Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least Squares linear regression\n",
    "\n",
    "Train and evaluate the LS regressor on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Least squares solution\n",
    "def least_squares(X_matrix: np.ndarray, labels: np.ndarray) -> None:\n",
    "    ## TODO: Run the LS algorithm without regularization\n",
    "\n",
    "def evaluate_model(x, y, coeff):\n",
    "    ## TODO: Return the average MSE for the set over which we evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the LS training and test it on the test data\n",
    "trained_model = least_squares(X_training, Y_training)\n",
    "mse = evaluate_model(X_test, Y_test, trained_model)\n",
    "print('Model coefficients:', trained_model)\n",
    "print('Root MSE:', np.sqrt(mse) * avg_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least Squares with Tikhonov regularization\n",
    "\n",
    "Perform K-fold cross validation with $\\lambda\\in\\{0, 0.1, 1, 10\\}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Least squares solution\n",
    "def regularized_least_squares(X_matrix: np.ndarray, labels: np.ndarray, lambda_par: np.ndarray) -> None:\n",
    "    ## TODO: Run the LS algorithm with regularization\n",
    "\n",
    "def K_fold(X_training: np.ndarray, Y_training: np.ndarray, lambda_vec: np.ndarray, K: np.ndarray) -> None:\n",
    "    ## TODO: Perform K-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the training with K-fold cross-validation and plot the score\n",
    "K = 5\n",
    "lambda_par = range(21)\n",
    "\n",
    "best_model, best_perf, models, results = K_fold(X_training, Y_training, lambda_par, K)\n",
    "print(best_model, results)\n",
    "plt.plot(lambda_par, np.sqrt(results) * avg_size)\n",
    "plt.xlabel('$\\lambda$')\n",
    "plt.ylabel('RMSE')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results for the regularized models on the test set\n",
    "test_scores = np.zeros(len(models))\n",
    "\n",
    "for i in range(len(models)):\n",
    "    test_scores[i] = evaluate_model(X_test, Y_test, models[i])\n",
    "\n",
    "plt.plot(lambda_par, np.sqrt(test_scores) * avg_size)\n",
    "plt.xlabel('$\\lambda$')\n",
    "plt.ylabel('RMSE')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXTRA\n",
    "\n",
    "Can you figure out the best amount of memory to use?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
